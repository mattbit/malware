""""""
import pandas as pd
import numpy as np
from tld.exceptions import TldDomainNotFound
from tld import get_fld


def extract_domain(url):
    try:
        return get_fld(url, fix_protocol=True)
    except Exception:
        return url

df = pd.concat([pd.read_json("data/2009-11-{:02}.json".format(i), lines=True)
                for i in range(1, 23)])
df["domain"] = df.to.apply(extract_domain)
cts = df.groupby("domain")["count"].sum()
cts = cts.sort_values(ascending=False)
cts.reset_index()
cts.shape
cts.plot(logx=True, logy=True)

# Bootstrapping
sample = df.domain.repeat(df["count"])
bootstrap = sample.sample(10000, replace=True)
bootstrap = pd.DataFrame(bootstrap)
bootstrap["request_count"] = 1
_cts = bootstrap.groupby("domain").request_count.count()
_cts = _cts.sort_values(ascending=False)
_cts.plot(logx=True, logy=True)



# HEADERS = ("time", "src", "dst", "protocol",
#            "http_host", "dns_host", "sni_host")
#
# df = pd.read_csv("../data/all.csv", header=None, names=HEADERS)
#
#
# def domain_name(record):
#     for field in ["http_host", "sni_host", "dns_host"]:
#         if not pd.isnull(record[field]):
#             return record[field]
#
#
# df["domain"] = df.apply(domain_name, axis=1)
# df = df.drop(columns=["http_host", "sni_host", "dns_host"])
#
# dx = df[~df.domain.str.endswith(".local").fillna(True)]
#
# # Write a csv with the preprocessed data.
# dx.to_csv("preprocessed.csv", index=False)
#
# df = pd.read_csv("preprocessed.csv")
# df.time
# # Letâ€™s build a graph linking
