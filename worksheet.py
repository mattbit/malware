"""Worksheet.

This notebook presents all the results used in the text (figures, estimations).
"""
import random
from collections import defaultdict
from math import log

import matplotlib.pyplot as plt
import networkx as nx
import numpy as np
import pandas as pd
import powerlaw
from tqdm import trange

from mlw.bp import LoopyBP
from mlw.mcmc import IsingMCMC

# plt.style.use("flat_publication")

###########################################################
# %% Load and pre-process the CTU dataset.                #
###########################################################

nf = pd.read_csv("data/ctu-13/capture20110810.binetflow")

# Keep only unidirectional TCP flows of more than 500 bytes.
nf.Dir = nf.Dir.str.strip()
nf = nf[(nf.Proto == "tcp") & (nf.TotBytes >= 500) & (nf.Dir == "->")]

# Discard the traffic between hosts in the local subnet (147.32.0.0/16).
# We only want to evaluate requests going from local hosts to the internet.
nf = nf[nf.SrcAddr.str.startswith("147.32.")
        & (~nf.DstAddr.str.startswith("147.32."))]

###########################################################
# %% Build the network graph based on the traffic flows.  #
###########################################################

flows = nf.loc[:, ("SrcAddr", "DstAddr")]
G = nx.Graph([(src, dst) for _, src, dst in flows.itertuples()])

# We want a connected graph, so we remove the few small isolated components and
# we keep the largest one.
G = G.subgraph(max([c for c in nx.connected_components(G)], key=len))

###########################################################
# %% Let's look at the characteristics of the graph.      #
###########################################################

assert nx.is_connected(G)
assert nx.is_bipartite(G)

degrees = list(dict(G.degree()).values())
fit = powerlaw.Fit(degrees, discrete=True, verbose=False)

ax = fit.plot_pdf(label="Empirical PDF")
fit.power_law.plot_pdf(color="navy", linestyle="--", alpha=0.5, label="Fit")
ax.set_ylabel("Fraction of nodes")
ax.set_xlabel("Node degree")
ax.legend()
plt.show()

print("Alpha = {:.5f}".format(fit.alpha))

# Look at the degree distribution for the two bipartite sets.
#
# A, B = nx.bipartite.sets(G)
#
# degrees_A = list(dict(G.degree(A)).values())
# degrees_B = list(dict(G.degree(B)).values())
# fit_A = powerlaw.Fit(degrees_A, discrete=True, verbose=False)
# fit_B = powerlaw.Fit(degrees_B, discrete=True, verbose=False)
#
# ax = fit_A.plot_pdf(label="Empirical PDF for set A")
# fit_B.plot_pdf(label="Empirical PDF for set B")
# fit_A.power_law.plot_pdf(color="navy", linestyle="--", alpha=0.5, label="Fit")
# fit_B.power_law.plot_pdf(color="navy", linestyle="--", alpha=0.5)
#
# ax.set_ylabel("Fraction of nodes")
# ax.set_xlabel("Node degree")
# ax.legend()
# plt.show()
# print("Alpha_A = {:.5f}\nAlpha_A = {:.5f}".format(fit_A.alpha, fit_B.alpha))

###########################################################
# %% Generate an artificial graph.                        #
###########################################################

p = powerlaw.Power_Law(xmin=1, parameters=[fit.alpha], discrete=True)
values = p.generate_random(200, estimate_discrete=True)
values = np.asarray(values, dtype=np.int)

G_a = nx.Graph()
nx.bipartite.preferential_attachment_graph(values, 0.5, create_using=G_a)
G_a = G_a.subgraph(max([c for c in nx.connected_components(G_a)], key=len))
assert nx.is_connected(G_a)

degrees_a = list(dict(G_a.degree()).values())
fit_a = powerlaw.Fit(degrees_a)
fit_a.alpha

# The two partitions corresponding to the local hosts and the outer domains.
hosts, domains = nx.bipartite.sets(G_a)

###########################################################
# %% Generate configurations with MCMC.                   #
###########################################################

BENIGN = 1
MALICIOUS = -1
P = {(BENIGN, BENIGN): 0.75, (BENIGN, MALICIOUS): 0.25,
     (MALICIOUS, BENIGN): 0.25, (MALICIOUS, MALICIOUS): 0.75}

print("""|--------------------------------|
|   i / j   | Benign | Malicious |
|--------------------------------|
| Benign    | {bb:6.2f} | {bm:9.2f} |
|-----------|--------|-----------|
| Malicious | {mb:6.2f} | {mm:9.2f} |
|--------------------------------|
""".format(bb=P[BENIGN, BENIGN], bm=P[BENIGN, MALICIOUS],
           mb=P[MALICIOUS, BENIGN], mm=P[MALICIOUS, MALICIOUS]))


# Random initial configuration.
nodes = list(G_a.nodes)
states = np.random.choice([BENIGN, MALICIOUS], size=len(nodes))
init_states = {}
fields = {}
for node, state in zip(nodes, states):
    init_states[node] = state
    fields[node] = 0

# Fix some known state (take a ~2% sample).
known = random.sample(domains, 150)
unknown = set(domains) - set(known)
malicious, benign = known[:75], known[75:]

for node in malicious:
    fields[node] = - np.inf  # surely malicious

for node in benign:
    fields[node] = np.inf  # surely benign

# %% Letâ€™s work in the potential domain (log probability).
J = log(P[BENIGN, BENIGN] / P[BENIGN, MALICIOUS]) / 2

sim = IsingMCMC(G_a, interaction=J, fields=fields, temperature=100)
states, energies = sim.run(init_states, 50)

plt.plot(energies)
plt.xlabel("Simulation time")
plt.ylabel("Energy")


###########################################################
# %% Now infer hidden state with belief propagation.      #
###########################################################

def evaluate_accuracy(graph, P, benign_domains, n):
    # Unknown, neutral prior.
    prior = defaultdict(lambda: {MALICIOUS: 0.5, BENIGN: 0.5})

    # Assume we know the benign domains and the state of n local hosts.
    known = set(benign_domains).union(random.sample(hosts, n))
    unknown = set(graph.nodes) - known
    for node in known:
        prior[node] = {MALICIOUS: float(states[node] == MALICIOUS),
                       BENIGN: float(states[node] == BENIGN)}

    # Run the max-product belief propagation
    bp = LoopyBP(graph, P, prior, [BENIGN, MALICIOUS])
    score = bp.run(reduce_func=max, tol=1e-9)

    correct_guesses = 0
    for node in G_a.nodes:
        inferred = max(score[node].keys(), key=(lambda key: score[node][key]))
        correct_guesses += inferred == states[node]

    return correct_guesses / len(unknown)

# %%
acc = np.zeros(len(hosts))
for n in trange(len(hosts) - 1, 0, -5):
    acc[n] = evaluate_accuracy(G_a, P, benign, n)
